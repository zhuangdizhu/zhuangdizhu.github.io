[{"authors":null,"categories":null,"content":"I am Zhu, Zhuangdi (Êú± Â∫ÑÁøü). I am currently a senior Data \u0026amp; Applied Scientist working with Microsoft. I received my PhD degree from the Department of Computer Science and Engineering, Michigan State University, advised by Professor Jiayu Zhou. I am an alumni member of the ILLIDAN Lab@MSU.\nMy research interest resides in both applied and fundamental machine learning. I am dedicated to developing principled algorithms that facilitate knowledge transfer across domains. My current research focuses on Reinforcement Learning and Federated Learning. My previous research involves systems, scheduling, and wireless networking. Some of my selected research topics:\nSample-efficient Reinforcement Learning from partially observable and suboptimal resource. Federated Learning with data and system heterogeneity. Robust and Fair learning with unsupervised data and distributed devices. üì¢üì¢ I will join the Department of Cyber Security Engineering at George Mason University as a tenure-track assistant professor in Jan 2024. I am looking for prospective Ph.D. students starting at Spring 2024 or Fall 2024. Please email me your CV if you are interested!\n","date":1654146500,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1654146500,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am Zhu, Zhuangdi (Êú± Â∫ÑÁøü). I am currently a senior Data \u0026amp; Applied Scientist working with Microsoft. I received my PhD degree from the Department of Computer Science and Engineering, Michigan State University, advised by Professor Jiayu Zhou.","tags":null,"title":"Zhuangdi Zhu","type":"authors"},{"authors":null,"categories":null,"content":" I have a cat named RiceCake. I love tennis, snowboarding, and swimming. I play Just Dance like a pro. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4455daaf58c62a24a21eb34fcd3bb907","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":" I have a cat named RiceCake. I love tennis, snowboarding, and swimming. I play Just Dance like a pro. ","tags":null,"title":"My Cat \"RiceCake\"","type":"authors"},{"authors":["Zhuangdi Zhu","Junyuan Hong","steve Drew","Jiayu Zhou"],"categories":null,"content":"","date":1654146500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654146500,"objectID":"cf1c2d6818282152a3069d0398353b0a","permalink":"https://zhuangdizhu.github.io/publication/fedrescue/","publishdate":"2022-06-02T13:08:20+08:00","relpermalink":"/publication/fedrescue/","section":"publication","summary":"The rise of Federated Learning (FL) is bringing machine learning to edge computing by utilizing data scattered across edge devices. However, the heterogeneity of edge network topologies and the uncertainty of wireless transmission are two major obstructions of FL's wide application in edge computing, leading to prohibitive convergence time and high communication cost. In this work, we propose an FL scheme to address both challenges simultaneously. Specifically, we enable edge devices to learn self-distilled neural networks that are readily prunable to arbitrary sizes, which capture the knowledge of the learning domain in a nested and progressive manner. Not only does our approach tackle system heterogeneity by serving edge devices with varying model architectures, but it also alleviates the issue of connection uncertainty by allowing transmitting part of the model parameters under faulty network connections, without wasting the contributing knowledge of the transmitted parameters. Extensive empirical studies show that under system heterogeneity and network instability, our approach demonstrates significant resilience and higher communication efficiency compared to the state-of-the-art.","tags":["Federated Learning","User-Heterogeneity","System Robustness"],"title":"Resilient and Communication Efficient Learning for Heterogeneous Federated Systems","type":"publication"},{"authors":["Zhuangdi Zhu","Kaixiang Lin","Bo Dai","Jiayu Zhou"],"categories":null,"content":"","date":1654146500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654146500,"objectID":"d14ee08fdc9d4b287cdf86b9e749abe1","permalink":"https://zhuangdizhu.github.io/publication/sail/","publishdate":"2022-06-02T13:08:20+08:00","relpermalink":"/publication/sail/","section":"publication","summary":"Reinforcement learning (RL) has demonstrated its superiority in solving sequential decision-making problems. However, heavy dependence on immediate reward feedback impedes the wide application of RL. On the other hand, imitation learning (IL) tackles RL without relying on environmental supervision by leveraging external demonstrations. In practice, however, collecting sufficient expert demonstrations can be prohibitively expensive, yet the quality of demonstrations typically limits the performance of the learning policy. To address a practical scenario, in this work, we propose SelfAdaptive Imitation Learning (SAIL), which, provided with a few demonstrations from a sub-optimal teacher, can perform well in RL tasks with extremely delayed rewards, where the only reward feedback is trajectory-wise ranking. SAIL bridges the advantages of IL and RL by interactively exploiting the demonstrations to catch up with the teacher and exploring the environment to yield demonstrations that surpass the teacher. Extensive empirical results show that not only does SAIL significantly improve the sample efficiency, but it also leads to higher asymptotic performance across different continuous control tasks, compared with the state-of-the-art.","tags":["Imitation Learning","Learning from Suboptimal Knowledge","Exploration in RL","Self-Adaptative Learning"],"title":"Self-Adaptive Imitation Learning: Learning Tasks with Delayed Rewards from Sub-Optimal Demonstrations.","type":"publication"},{"authors":["Zhuangdi Zhu","Junyuan Hong","Jiayu Zhou"],"categories":null,"content":"","date":1622610500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622610500,"objectID":"f192962198285231aeb8c533766deb58","permalink":"https://zhuangdizhu.github.io/publication/fedgen/","publishdate":"2021-06-02T13:08:20+08:00","relpermalink":"/publication/fedgen/","section":"publication","summary":"Federated Learning (FL) is a decentralized machine-learning paradigm, in which a global server iteratively averages the model parameters of local users without accessing their data. User heterogeneity has imposed significant challenges to FL, which can incur drifted global models that are slow to converge. Knowledge Distillation has recently emerged to tackle this issue, by refining the server model using aggregated knowledge from heterogeneous users, other than directly averaging their model parameters. This approach, however, depends on a proxy dataset, making it impractical unless such a prerequisite is satisfied. Moreover, the ensemble knowledge is not fully utilized to guide local model learning, which may in turn affect the quality of the aggregated model. Inspired by the prior art, we propose a data-free knowledge distillation approach to address heterogeneous FL, where the server learns a lightweight generator to ensemble user information in a data-free manner, which is then broadcasted to users, regulating local training using the learned knowledge as an inductive bias. Empirical studies powered by theoretical implications show that our approach facilitates FL with better generalization performance using fewer communication rounds, compared with the state-of-the-art.","tags":["Federated learning","Data-Heterogeneity","Non-IID"],"title":"Data-Free Knowledge Distillation for Heterogeneous Federated Learning","type":"publication"},{"authors":["Zhuangdi Zhu","Kaixiang Lin","Bo Dai","Jiayu Zhou"],"categories":null,"content":"","date":1591074500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591074500,"objectID":"f8a6913f2fd18d518550e7d8b1ec9d98","permalink":"https://zhuangdizhu.github.io/publication/opolo/","publishdate":"2020-06-02T13:08:20+08:00","relpermalink":"/publication/opolo/","section":"publication","summary":"Learning from Observations (LfO) is a practical reinforcement learning scenario from which many applications can benefit through the reuse of incomplete resources. Compared to conventional imitation learning (IL), LfO is more challenging because of the lack of expert action guidance. In both conventional IL and LfO, distribution matching is at the heart of their foundation. Traditional distribution matching approaches are sample-costly which depend on on-policy transitions for policy learning. Towards sample-efficiency, some off-policy solutions have been proposed, which, however, either lack comprehensive theoretical justifications or depend on the guidance of expert actions. In this work, we propose a sample-efficient LfO approach which enables off-policy optimization in a principled manner. To further accelerate the learning procedure, we regulate the policy update with an inverse action model, which assists distribution matching from the perspective of mode-covering. Extensive empirical results on challenging locomotion tasks indicate that our approach is comparable with state-of-the-art in terms of both sample-efficiency and asymptotic performance.","tags":["Reinforcement learning","Sample-Efficiency","Partial Observability","Imitation Learning"],"title":"Off-Policy Imitation Learning from Observations","type":"publication"},{"authors":null,"categories":null,"content":"","date":1580083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580083200,"objectID":"97608cdd2a37e1780fe46591f07dbfdf","permalink":"https://zhuangdizhu.github.io/project/federated-learning/","publishdate":"2020-01-27T00:00:00Z","relpermalink":"/project/federated-learning/","section":"project","summary":"On the need of data privacy and more data, we strive to join the knowledge from a fair amount of users to train powerful deep neural networks without sharing data.","tags":["Machine Learning","Federated Learning","Distributed Learning"],"title":"Federated Learning","type":"project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://zhuangdizhu.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Junyuan Hong"],"categories":["machine-learning"],"content":"Keras provides very convenient tools for fast protyping Machine Learning models, especially neural networks. You can pass metric functions when compiling a model, to evaluate the learnt models. However in the current version (after v2.0.0), Keras no longer provides widely used binary-classification metrics, e.g., recall, f1score, etc. The reason is clearly explained in keras issue #5794. In this posts, we are going to dicuss a working-around to evaluate these metrics with Keras.\nWhy not use global metrics That is the metrics evaluated in Keras are batch-wise only. The epoch output metric values are averaged like: $${\\sum \\text{(batch metric)} * \\text{(batch size)} \\over \\text{(# batch)} * \\text{(batch size)}}$$. This is okay for batch-wise metric like accuracy: $${\\sum \\text{(batch #TP + #TN)/(batch size)} * \\text{(batch size)} \\over \\text{(# batch)} * \\text{(batch size)}} = {\\text{(#TP + #TN)} \\over \\text{(total #sample)}}$$. For global metrics, e.g., recall, the average is improper: $${\\sum \\text{(batch #TP)/(batch #TP + #FN)} * \\text{(batch size)} \\over \\text{(# batch)} * \\text{(batch size)}} \\neq {\\text{(#TP)} \\over \\text{(total #TP + #FN)}}$$. Of course, when you use a relatively large batch size and a large number of batches, the average will be close to the global value. However, there will aften be a large gap between the average and global value. Especially for AUC value, the computation is danguous.\nIf you don\u0026rsquo;t mind the bias caused by the average, you could use metrics passed to model.compile(...), e.g.:\ndef recall(y_true, y_pred, is_categorical=True): \u0026quot;\u0026quot;\u0026quot;Recall metric.\tOnly computes a batch-wise average of recall.\tComputes the recall, a metric for multi-label classification of\thow many relevant items are selected.\t\u0026quot;\u0026quot;\u0026quot; true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) possible_positives = K.sum(K.round(K.clip(y_true, 0, 1))) recall = true_positives / (possible_positives + K.epsilon()) return recall It is notable that the K.epsilon() has to be used in the division, because possible_positives could be zero in one batch.\nExisting solutions Batch-wise estimation In addtion to the example mentioned above, there are some discussion on the batch-wise estimation.\nDecorate tensorflow metrics: How to calculate precision and recall in Keras, which seems not working now. Better Practice Predict and evaluate metrics Compute the global metric value on epoch end.\nclass Metrics(keras.callbacks.Callback): def __init__(self, validation_data): self.validation_data = validation_data def on_epoch_end(self, batch, logs={}): predict = np.asarray(self.model.predict(self.validation_data[0])) targ = self.validation_data[1] self.f1s=f1(targ, predict) return metrics = Metrics([X_test,y_test]) model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=[X_test,y_test], verbose=1, callbacks=[metrics]) [Source codes from comment in Keras issue # 5794]\nHowever, this solution will be time-comsuming to run model.predict on the epoch end. The prediction procdure is actually evaluated during training. The repitation is wasteful.\nA keras-metrics package One thought to tackle the issue is to fetch predictions from the model and then evaluate metrics. A close solution is given in keras-metrics. In the package, they create a class to store history record of true positive, false positive and so on. However the test case and example given by the authors cannot demonstrate the effectiveness. One drawback of their solution is that they do not solve the averaging problem.\nHowever, the keras-metrics package is only effective in the Keras (\u0026gt;=v2.1.6) which will avoid averaging metrics which are stateful Layer instances. Look at BaseLogger\nOfficial updates in Keras v2.1.6 for stateful metrics Until today, there has been some updates in Keras. You can find Pull-Request: PR#9253: Add support for stateful metrics. and PR#9446: General stateful metrics fixes. However there is still no official metrics for recall, f1score etc.\nCustomize stateful metrics If you have update Keras to v2.1.6 which supports \u0026lsquo;stateful metrics\u0026rsquo;, then you can try to customize some metric like the one in StackOverflow.\nThe best reference is the BinaryTruePositives class provided by Keras test case.\n","date":1542342281,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542342281,"objectID":"f2af8796af586e7ec72237af18b5bcc6","permalink":"https://zhuangdizhu.github.io/post/keras-eval-binary-classification/","publishdate":"2018-11-15T23:24:41-05:00","relpermalink":"/post/keras-eval-binary-classification/","section":"post","summary":"Keras provides very convenient tools for fast protyping Machine Learning models, especially neural networks. You can pass metric functions when compiling a model, to evaluate the learnt models. However in the current version (after v2.","tags":["Keras","Machine Learning"],"title":"Evaluate Binary Classification with Keras","type":"post"},{"authors":["Junyuan Hong"],"categories":["tech"],"content":"When refactoring a codes, we need to extract duplicated features from different methods or functions. A magic in Python 3 is to decorate the a striped basic functions with sharing features.\nWhat is decorator? A (almost) minimal demo:\nfrom functools import wraps def my_decorator(func): # to make sure func name are included. @wraps(func) def wrapper(x): \u0026quot;\u0026quot;\u0026quot; function wrapper of my_decorator \u0026quot;\u0026quot;\u0026quot; print(\u0026quot; Hi, \u0026quot;) + func.__name__ + \u0026quot; return.\u0026quot;) return func(x) return wrapper # use decorator @my_decorator def foo(x): return x + 1 foo(10) Why decorator? Memoization: speed up function evaluation by storing the {input: output} dict. Decorate a function with additional processes which probably are duplicated from other funcs. For example, you can count the evaluation times in a decorator. Use class as a decorator You can transform class into function by adding a __call__ method to the class.\nDecorator demo:\nclass my_decorator: def __init__(self, f): self.f = f def __call__(self): print(\u0026quot;Decorating \u0026quot;, self.f.__name__) self.f() @my_decorator def foo(): print(\u0026quot;hello from foo\u0026quot;) Further reading: Python3 decorators tutorial\n","date":1542300426,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542300426,"objectID":"8654577e2e6e43d15ccfa5ba11087dd2","permalink":"https://zhuangdizhu.github.io/post/python-decorator/","publishdate":"2018-11-15T11:47:06-05:00","relpermalink":"/post/python-decorator/","section":"post","summary":"When refactoring a codes, we need to extract duplicated features from different methods or functions. A magic in Python 3 is to decorate the a striped basic functions with sharing features.\n","tags":["Python"],"title":"Python Decorator","type":"post"},{"authors":null,"categories":null,"content":"","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538006400,"objectID":"4aef9d19fd9dee16ec71211c4b827fc6","permalink":"https://zhuangdizhu.github.io/project/private-learning/","publishdate":"2018-09-27T00:00:00Z","relpermalink":"/project/private-learning/","section":"project","summary":"On the concern of data privacy, we aim to develop algorithms towards learning accurate models privately from data.","tags":["Machine Learning","Differential Privacy"],"title":"Differentially Private Learning","type":"project"},{"authors":null,"categories":["How-to"],"content":"As a MS student, I am going to leave my lab at USTC. With this post, I\u0026rsquo;d like to share my experiences on the Linux system, especially for those who are new to such a system.\nPart 1: Introduction For whom is the post written? The audiances are expected to be\nThe first-year student for MSc of CS. He/She is to do research on fields, including Software Developing, Maching Learning and related directions. He/She eager to pay time to solve issues by themselves in the future. In addition, it\u0026rsquo;s better to clarify who is not the potential audiances:\nWho expect to find all solutions to their works on Linux. The space is limit so as not possible to do that. Who expect to be a master of the problems introduced here. This is an small cookbook, not encyclopedia. Most importantly, remember that I am just a student, but not a master in these fields. Thus, there is hich chance that I could be wrong.\nWhy English rather than Chinese? You may wonder why the post is written in English, while the readers are mostly speaking Chinese. This is just my opinion that:\nEnglish is more efficient for people to find answers from Google, stackoverflow and so on. English is in every corner of the programmers\u0026rsquo; world, in the documents of python language, in the books of cutting-edge techniques and so on. The comments and programming variables are in English. When you are familiar with English, esp. some special terminologies, it\u0026rsquo;s more possible for you to understand the comments, variables and therefore the codes. How this post will be organized? Basically, I will organize the post centered in several crucial tasks:\nHow to access files you want? How to run Matlab codes? How to submit a PBS job? These questions are under the conditions:\nThere is no monitor (or screen) if not specified. Some concepts:\nshell: it is actually the command line tool you used in the Linux to interact with the whole system. bash: it is one kind of shell. If not specified, I refer shell to bash here. Both bash and shell are softwares. Ubuntu: A Linux system. Now, let\u0026rsquo;s rock!\nPart 2: Access your files This is the very first question to every Linux user: Where can I find my files? or How can I handle my files? This question could include several parts. I will demonstrate them with comments (started with #). The exected shell commands are displayed with a $ at the begining.\n$ ls # (l)i(s)t all files under current folder $ cd hello # (C)hange (D)irectory to 'hello' folder $ vim aa.txt # edit text file or any other files. `vim` is a software $ rm aa.txt # (R)e(M)ove file $ cp aa.txt bb.txt # (c)o(p)y from aa.txt to bb.txt $ man cp # open the manual of command `cp`, and press `q` to quit. $ cat aa.txt # print the content $ ssh jyhong@129.0.0.1 # log into server: `ssh \u0026lt;username\u0026gt;@\u0026lt;server address or IP\u0026gt;` Part 3: Run Matlab codes There are two ways to do that. One is with your familiar window, while the other is simply a commandline tool.\nRun locally-like You must be familiar with Matlab\u0026rsquo;s Graphic User Interface (GUI). It could freak me out when I found I can do things with the familiar interface. But, soon, it turns out that it\u0026rsquo;s unnecessary. The strategy is based on forwarding x-window. See Use GUI software remotely for more information. Here are commands:\n$ ssh -X ubri # '-X' means the remote GUI display will be forwarded to local. $ jyhong@ubri \u0026gt; matlab # run the matlab Then you should get into your familiar zone. If no GUI window appears, try one of these:\nRun Matlab using absolute path. Check the ~/.bashrc file, if there is a setting of matlab to disable GUI, e.g., matlab -nodisplay will do that. Run in command line It is straightforward to run Matlab in command line. Just run matlab. If the command is not found, add below line to your ~/.bashrc\nalias matlab=\u0026quot;/opt/MATLAB/R2016a/bin/matlab -nodisplay -singleCompThread\u0026quot; which use the command matlab to represent the later long one.\nPart 4: Submit a PBS job When you first log into the server, you could see some information about the job management sysetm, torque1 2.\nSome common steps:\nCopy the template.pbs file: cp template.pbs myjob.pbs Add your run command to the last line of the pbs file. Submit it: qsub myjob.pbs or\nqsub -d `pwd` myjob.pbs Part 5: Useful tools Use GUI software remotely Basically, you can run any GUI software remotely after you log in with below comnand:\n$ ssh -X urbi Unless the remote system is not GUI-based. For example, the server version of Ubuntu. The operation is supported natively by most Linux desktop system. If you want to use it at Windows, try XShell (See \u0026lsquo;Launch X Applications Through an SSH Tunnel\u0026rsquo; feature), which is a powerful tool for using ssh.\nhttp://bicmr.pku.edu.cn/~wenzw/pages/batch.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttp://docs.adaptivecomputing.com/torque/4-0-2/Content/topics/commands/qsub.htm\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":1528711906,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528711906,"objectID":"77b619f0ee8fbdc764f88005ceb6e68b","permalink":"https://zhuangdizhu.github.io/post/linux-rookie/","publishdate":"2018-06-11T18:11:46+08:00","relpermalink":"/post/linux-rookie/","section":"post","summary":"As a MS student, I am going to leave my lab at USTC. With this post, I\u0026rsquo;d like to share my experiences on the Linux system, especially for those who are new to such a system.\n","tags":["Linux","How-to"],"title":"Linux Rookie Book","type":"post"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"087fe6559a3f9709a3e9dc9f2080d72e","permalink":"https://zhuangdizhu.github.io/project/subspace-learning/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/subspace-learning/","section":"project","summary":"Supervised learning on subspace data which could model real data like skeleton motion.","tags":["Machine Learning"],"title":"Subspace Learning","type":"project"},{"authors":null,"categories":["tech"],"content":" Reference: Using auto-layout to calculate table cell height\nIn \u0026lsquo;Using auto-layout to calculate table cell height\u0026rsquo;, it\u0026rsquo;s introduced how to use auto-layout to update table view\u0026rsquo;s (UITableView) cell height with Objective-C language. However there is different at NSTableView.\nHere I will introduce to do similar thing at NSTableView with Swift language. Remember one thing post \u0026lsquo;Using auto-layout to calculate table cell height\u0026rsquo; has warned that this method is not that efficient, figure out the way make it more efficient yourself.\nAssuming you have been familiar with the mechanism of NSTableView, including NSTableViewDelegate and NSTableViewDataSource, I will not introduce these knowledge in detail below.\nWhen configure table cell view, it\u0026rsquo;s helpful later if you seperate some configure functions.\nfunc tableView(tableView: NSTableView, viewForTableColumn tableColumn: NSTableColumn?, row: Int) -\u0026gt; NSView? { var cell = tableView.makeViewWithIdentifier(\u0026quot;InMessageCellView\u0026quot;, owner: self) if let cl = cell { // Do data configures in 'configureCell' function. cell = configureCell(cl, row: row) } return cell } Then tell NSTableView the height of row:\nlet defaultRowHeight = CGFloat(36) func tableView(tableView: NSTableView, heightOfRow row: Int) -\u0026gt; CGFloat { var cell = tableView.makeViewWithIdentifier(\u0026quot;InMessageCellView\u0026quot;, owner: self) if let cl = cell { cell = configureCell(cl, row: row) // Let NSView to update its layout automatically. cell!.layoutSubtreeIfNeeded() // Return the updated frame height. // Remember to setup constraints in Xcode's stroyboard, which should limit // the cell's height corespond to subview(like text view). return cell!.frame.height } return defaultRowHeight } Refer from Apple\u0026rsquo;s documentation:\nAlthough table views may cache the returned values, you should ensure that this method is efficient.\nSo be careful about performance, read more about it to visit reference1 .\nReference Using Auto Layout in UITableView for dynamic cell layouts \u0026amp; variable row heights\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":1438683106,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438683106,"objectID":"8351bf7499ff25835d5c102886e0432d","permalink":"https://zhuangdizhu.github.io/post/2015-08-04-nstableview-automatically-adjust-height-to-fit-cell-view/","publishdate":"2015-08-04T18:11:46+08:00","relpermalink":"/post/2015-08-04-nstableview-automatically-adjust-height-to-fit-cell-view/","section":"post","summary":"Reference: Using auto-layout to calculate table cell height\nIn \u0026lsquo;Using auto-layout to calculate table cell height\u0026rsquo;, it\u0026rsquo;s introduced how to use auto-layout to update table view\u0026rsquo;s (UITableView) cell height with Objective-C language.","tags":["OS X","Xcode","Cocoa"],"title":"NSTableView automatically adjust height to fit cell view","type":"post"},{"authors":null,"categories":["tech"],"content":" To make a iMessage-like chat table view, there is several steps to follow:\nText field should be able to adjust its size automatically. Image view of bubble should adjust automatically relative to text field. Table view\u0026rsquo;s row should be fitted into the row cell\u0026rsquo;s subview, which include text field and image view. Let scroller auto scroll to bottum. Here I use View-based NSTableView to make these:\nTable view settings There is some import constraints to make the three components, NSImageView, NSTextField, NSTableViewCell, keep corresponded size, which is showed below:\nCell contraint settings You should set NSTextField like below, which will make it auto adjust size to text:\nText field settings Then use NSTableViewDelegate to adjust height. Read this post: NSTableView automatically adjust height to fit cell view.\nFinally, when you add a new row at bottum, you will hope the scroller to scroll to bottum.\ndispatch_async(dispatch_get_main_queue(), { () -\u0026gt; Void in // tableView is IBOutlet refer to table view. self.tableView.insertRowsAtIndexes(NSIndexSet(index: self.tableView.numberOfRows), withAnimation: NSTableViewAnimationOptions.EffectNone) self.tableView.noteHeightOfRowsWithIndexesChanged(NSIndexSet(index: self.tableView.numberOfRows - 1)) // scroll self.tableView.scrollRowToVisible(self.tableView.numberOfRows - 1) }) ","date":1438683080,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438683080,"objectID":"26b6459397ef6b97c6e0bc5c06522da3","permalink":"https://zhuangdizhu.github.io/post/2015-08-04-make-text-table-viewnstableview-auto-resize/","publishdate":"2015-08-04T18:11:20+08:00","relpermalink":"/post/2015-08-04-make-text-table-viewnstableview-auto-resize/","section":"post","summary":"To make a iMessage-like chat table view, there is several steps to follow:\nText field should be able to adjust its size automatically. Image view of bubble should adjust automatically relative to text field.","tags":["OS X","Xcode","Cocoa"],"title":"Make text table view(NSTableView) auto resize","type":"post"},{"authors":null,"categories":["tech"],"content":" Dynamic library (with .dylib suffix at UNIX-like OS) is a kind of library discriminated from static library (with .a suffix). Static library will be linked at linking stage instantly after codes are compiled, before binary product output. And instead library is loaded at runtime, I mean load but not link. Load means the executable file will search for binary library when they need it. That\u0026rsquo;s why some app will announce you that it lack a lib when you double click them for running happily. In contrast, static library will compile these needed part into you app, so the user will not be bothered.\nThen why we use dynamic library? That\u0026rsquo;s file size! A static library is several times bigger than a same function dynamic library. For example the SDL lib at OS X, which is located at /usr/local/Cellar/sdl2/2.0.3/lib/ if you install it through Homebrew.\n$ ls /usr/local/Cellar/sdl2/2.0.3/lib/ -lh -r--r--r-- 1 user admin 850K Jul 20 22:18 libSDL2-2.0.0.dylib -r--r--r-- 1 user admin 1.5M Oct 22 2014 libSDL2.a There are two method to add 3rd-part dynamic library to a Xcode target:\nInstall the library into your system Copy your library into your product. Method 1: Install the library For most library, 3rd part library can be installed into system, at /usr/local/lib or /usr/lib. Then just add header path to Xcode target \u0026gt; Build Setting, if the header file is not be found by Xcode. Finally, link your library at Xcode target \u0026gt; Build Phase \u0026gt; Linked Libraries and Frameworks.\nHowever, this method doesn\u0026rsquo;t allow your app user to use app freely, since it require the user to install the library too. That\u0026rsquo;s terrible for an app.\nMethod 2: Copy .dylib file into your product So it\u0026rsquo;s obvious that a better way to use dynamic library is bundle the .dylib with .app file. Path relative yourself is better than relative to system.\nHow the executable binary file inform system which and where library is needed?\nSince a program starts from its binary file, file is the only one from who system can get information about linked library. Or we can say the binary file is the bridge between developer and user\u0026rsquo;s system, compiler and linker are the builders. So, we should ask the binary file for the answer directly with otool provided by OS X.\nAssume I have a project named Vivi, output file Vivi.app . Vivi used two of my framework named ViviSwiften.framework and ViviInterface.framework , they are in the same project as Vivi. Although you run an App by double click it, but it\u0026rsquo;s not a binary file indeed. The executable binary file is located at AppName.app/Contents/MacOS/AppName instead.\nAsk Vivi binary file:\n$ otool -L Vivi.app/Contents/MacOS/Vivi Vivi.app/Contents/MacOS/Vivi: @rpath/ViviInterface.framework/Versions/A/ViviInterface (compatibility version 1.0.0, current version 1.0.0) @rpath/ViviSwiften.framework/Versions/A/ViviSwiften (compatibility version 1.0.0, current version 1.0.0) /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1223.0.0) /System/Library/Frameworks/AppKit.framework/Versions/C/AppKit (compatibility version 45.0.0, current version 1387.1.0) /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation (compatibility version 150.0.0, current version 1225.0.0) /usr/lib/libobjc.A.dylib (compatibility version 1.0.0, current version 228.0.0) @rpath/libswiftAppKit.dylib (compatibility version 0.0.0, current version 0.0.0) @rpath/libswiftCore.dylib (compatibility version 0.0.0, current version 0.0.0) @rpath/libswiftCoreData.dylib (compatibility version 0.0.0, current version 0.0.0) @rpath/libswiftCoreGraphics.dylib (compatibility version 0.0.0, current version 0.0.0) ... It seems that otool print the list of path of all linked libraries and their version messages.\nWell, there is so many stuffs. Hey, I found there is my frameworks, ViviSwiften.framework and ViviInterface.framework. Okay, I know ViviInterface.framework/Versions/A/ViviInterface is the path point to the binary file of the framework (Different from .app file, framework\u0026rsquo;s binary file is located at FrameworkName.framework/Versions/A/FrameworkName commonly), but what the @rpath means.\nWhat\u0026rsquo;s @excutable_path, @loader_path and @rpath?1 2 3 The three variable is defined at runtime:\n@executable_path, this always point to the product executable binary file path, AppName.app/Contents/MacOS/AppName. @loader_path, this is dependent on which is the loader. For example, my Vivi.app load the ViviSwiften.framework, then a dylib linked by ViviSwiften.framework could get two variable @loader_path=/path/to/ViviSwiften.framework/Versions/A/, and @executable_path=/path/to/Vivi.app/Contents/MacOS/. @rpath, this is just a path stored some predefined path. You can set it at Xcode target \u0026gt; Build Setting \u0026gt; Runpath Search Path. Often there will include @executable_path/../Frameworks for an App target, @executable_path/../Frameworks and @loader_path/Frameworks for a Framework target, @executable_path/../Frameworks and @loader_path/../Frameworks for a Unit Test target. Now we know Vivi.app used ViviSwiften.framework and ViviInterface.framework created by myself, and other system frameworks or libraries. But there is no 3rd part dynamic libraries added by myself (the dylib linked in Vivi.app is auto added by Xcode). The libraries is libSwiften.3.0.dylib which is linked in ViviSwiften.framework. Let\u0026rsquo;s ask ViviSwiften if that is true.\n$ otool -L ViviSwiften.framework/Versions/A/ViviSwiften ViviSwiften.framework/Versions/A/ViviSwiften: @rpath/ViviSwiften.framework/Versions/A/ViviSwiften (compatibility version 1.0.0, current version 1.0.0) @loader_path/Frameworks/libSwiften.3.0.dylib (compatibility version 3.0.0, current version 3.0.0) /System/Library/Frameworks/Security.framework/Versions/A/Security (compatibility version 1.0.0, current version 57301.0.0) ... You can see that ViviSwiften.framework used a 3rd part dynamic library libSwiften.dylib with path @loader_path/Frameworks/libSwiften.3.0.dylib.\nHow system find these libraries or frameworks? (Vivi example) User double clicks to run Vivi.app. Vivi.app executes Vivi.app/Contents/MacOS/Vivi. Search for dynamic libraries and frameworks needed by Vivi.app. Found @rpath/ViviSwiften.framework/Versions/A/ViviSwiften, which is transferred to @executable_path/../Frameworks/ViviSwiften/ then transferred to Vivi.app/Contents/MacOS/Vivi/../Frameworks/ViviSwiften.framework . Search for dynamic libraries and frameworks needed by ViviSwiften.framework. Found @loader_path/Frameworks/libSwiften.3.0.dylib which has been transferred to ViviSwiften.framework/Version/A/Frameworks/libSwiften.3.0.dylib. How these messages are written into binary file? Well, we know the messages are inside the binary file, but how they get into there? There are two hard woking builder: compiler and linker. Compiler will mark the needed symbols and pass to linker, Linker will find symbols in libraries you told it. Finally linker will write the needed libraries into executable binary file. If you provide a static library, linker will write the whole file into binary file. Or if you provide a dynamic library, only library path will be written into binary file.\nWhere does linker get the path from? Unfortunately the path is not provided by developer of the App but the 3rd part library developer. So you can not let Xcode use the path relative your product or use path provided by yourself.\nLet\u0026rsquo;s review ViviSwiften.framework\u0026rsquo;s answer to otool:\n$ otool -L ViviSwiften.framework/Versions/A/ViviSwiften ViviSwiften.framework/Versions/A/ViviSwiften: @rpath/ViviSwiften.framework/Versions/A/ViviSwiften (compatibility version 1.0.0, current version 1.0.0) @loader_path/Frameworks/libSwiften.3.0.dylib (compatibility version 3.0.0, current version 3.0.0) ... We found the first line is the path to ViviSwiften itself. So\u0026hellip;that\u0026rsquo;s it.\nThe path describing the self path is called install_name.\nThe path provided by ViviSwiften.framework is the correct path as described above. But will the 3rd part library always provide correct path as we expected? No!\nWhat path will compiled 3rd part library provide? There is two situations:\nYou have installed the library with Homebrew or from source (like make install ). The library will provide path like: /usr/lib/libxxx.dylib, /usr/local/lib/libxx.dylib. You just compiled source with ./configure \u0026amp;\u0026amp; make , then the library may provide path like: libxx.dylib without prefix. Both situation is not expected.\nChange the install_name to expected OS X provide another tool named install_name_tool for change install_name and linked lib install_name.\n# change linked lib path $ install_name_tool -change old new bin_file # change the library install_name $ install_name_tool -id new_install_name bin_file The whole strategy As a conclusion, the strategy for adding 3rd part dynamic library into Xcode target is:\nAdd library to Build Phase, and add header to search path. This guarantee no compile and link error will occur. Let Xcode copy .dylib file into product after compiled. Add \u0026ldquo;New Copy Files Phase\u0026rdquo;, name it \u0026ldquo;Copy Libraries\u0026rdquo; new copy phase Set the \u0026ldquo;Destination\u0026rdquo; to \u0026ldquo;Frameworks\u0026rdquo;. Add your dylib here.link_dynamic_lib Change install_name of library: $ install_name_tool -id @loader_path/Frameworks/libSwiften.3.0.dylib libSwiften.3.0.dylib That\u0026rsquo;s all.\nReference Build Settings‰∏≠ÁöÑÂèòÈáè@rpath,@loader_path,@executable_path.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOS X Man Page: dyld(1) ‚Äì Apple Developer\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRun-Path Dependent Libraries ‚Äì Apple Developer\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":1438164706,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438164706,"objectID":"0959831b9d3a1c02caa95dde437051e3","permalink":"https://zhuangdizhu.github.io/post/2015-07-29-add-3rd-part-dynamic-library-dylib-to-xcode-target/","publishdate":"2015-07-29T18:11:46+08:00","relpermalink":"/post/2015-07-29-add-3rd-part-dynamic-library-dylib-to-xcode-target/","section":"post","summary":"Dynamic library (with .dylib suffix at UNIX-like OS) is a kind of library discriminated from static library (with .a suffix). Static library will be linked at linking stage instantly after codes are compiled, before binary product output.","tags":["Xcode","OS X"],"title":"Add 3rd part dynamic library (.dylib) to Xcode target","type":"post"},{"authors":null,"categories":["tech"],"content":" According to the SceneKit document, the function of resetTransform is:\nUpdates the position and orientation of a body in the physics simulation to match that of the node to which the body is attached.\nThrough experiment, I found this is little special.\nIf you do this:\nvar node = SCNNode(geomentry: SCNBox()) node.position = SCNVector3(0, 1, 0) node.rotation = SCNVector4(1, 0, 0, CGFloat(M_PI)/2) node.physicsBody = SCNPhysicsBody(type: .Dynamic, nil) scene.rootNode.addChildNode(node) If you get the position and rotation of node.presentationNode() in the render delegate, where I mean you need to get the latest and real data, you will found the effect of the setup of node\u0026rsquo;s position and rotation is not work at the begining.\nAt the begining, the position will be (0, 0, 0), but not what you have set, (0, 1, 0).\nIf you have read the document about SCNNode.position and SCNNode.rotation, you will found:\nposition\nThe translation applied to the node. Animatable.\nThe Animatable means it will take several frames to get the effect.\nHowever, it\u0026rsquo;s different when you use resetTransform of SCNPhysicsBody:\nvar node = SCNNode(geomentry: SCNBox()) node.position = SCNVector3(0, 1, 0) node.rotation = SCNVector4(1, 0, 0, CGFloat(M_PI)/2) node.physicsBody = SCNPhysicsBody(type: .Dynamic, nil) scene.rootNode.addChildNode(node) node.physicsBody.resetTransform() The effect will work at the begining.\n","date":1423044706,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1423044706,"objectID":"cc2dc434236f802a481ff38712016b91","permalink":"https://zhuangdizhu.github.io/post/2015-02-04-resettransform-at-scnphysicsbody/","publishdate":"2015-02-04T18:11:46+08:00","relpermalink":"/post/2015-02-04-resettransform-at-scnphysicsbody/","section":"post","summary":"According to the SceneKit document, the function of resetTransform is:\nUpdates the position and orientation of a body in the physics simulation to match that of the node to which the body is attached.","tags":["Cocoa","SceneKit"],"title":"The method resetTransform of SCNPhysicsBody","type":"post"},{"authors":null,"categories":["website"],"content":" NOTE: this article is first posted in my old website, which has be deprecated.\nJekyll is a powerful static website framework, which indead works for GitHub Pages. At the time I found it, I decided to apply it for my github.io as you can see.\nSome useful webpages for install Jekyll at github.io:\nHost on GitHub in 3 Minutes\nActually you need only to clone the Jekyll in your gihub.io, or just copy all file from Jekyll.\nJekyll advise you to clone the jekyll to local with your name and push it to your github.\ngit clone https://github.com/plusjade/jekyll-bootstrap.git USERNAME.github.io cd USERNAME.github.com git remote set-url origin git@github.com:USERNAME/USERNAME.github.io git push origin master But if you have already create a repository at GitHub, you can also copy the files from jekyll to your repository.\ngit clone https://github.com/plusjade/jekyll-bootstrap.git jekyll-bootstrap cd jekyll-bootstrap cp -r ./* router/to/USERNAME.github.io cd router/to/USERNAME.github.io git push origin master It also works honestly.\nAnother web about the Jekyll and GitHub: Using Jekyll and GitHub Pages for Our Site\nIn the _config.yml, you can add some tools:\nJekyll is easy to add Disqus for comments. You can visit DISQUS for more details.\nYou can also use Google Analytics to track your website.\n","date":1422958306,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1422958306,"objectID":"d03dad507abe8e6e10e287d772c2d8fd","permalink":"https://zhuangdizhu.github.io/post/2015-02-03-start-my-blog-with-jekyll-and-disqus/","publishdate":"2015-02-03T18:11:46+08:00","relpermalink":"/post/2015-02-03-start-my-blog-with-jekyll-and-disqus/","section":"post","summary":"NOTE: this article is first posted in my old website, which has be deprecated.\nJekyll is a powerful static website framework, which indead works for GitHub Pages. At the time I found it, I decided to apply it for my github.","tags":["Linux","How-to","jekyll"],"title":"Start my blog with Jekyll and disqus","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://zhuangdizhu.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]