[{"authors":null,"categories":null,"content":"I am Zhu, Zhuangdi (æœ± åº„ç¿Ÿ). I am a tenure-track assistant professor at the Department of Cyber Security Engineering of George Mason University. Prior to that I worked as a senior Data \u0026amp; Applied Scientist for Microsoft. I received my Ph.D. degree from the Department of Computer Science and Engineering, Michigan State University, advised by Dr. Jiayu Zhou.\nMy research interest resides in both applied and fundamental machine learning. I am dedicated to developing principled algorithms that facilitate knowledge transfer across domains. My current research focuses on Federated Learning and Reinforcement Learning. My previous research involves systems, scheduling, and wireless networking. Some of my selected research topics:\nFederated Learning with data and system heterogeneity. Sample-efficient Reinforcement Learning from partially observable and suboptimal resource. Robust and Fair learning with unsupervised data and distributed devices. ðŸ“¢ðŸ“¢ I am actively looking for prospective Ph.D. students and research interns. Please email me your CV, transcript, and a Statement of Purpose if you are interested!\n","date":1695445700,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1695445700,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am Zhu, Zhuangdi (æœ± åº„ç¿Ÿ). I am a tenure-track assistant professor at the Department of Cyber Security Engineering of George Mason University. Prior to that I worked as a senior Data \u0026amp; Applied Scientist for Microsoft.","tags":null,"title":"Zhuangdi Zhu","type":"authors"},{"authors":null,"categories":null,"content":" I have a cat named RiceCake. I love tennis, snowboarding, and swimming. I play Just Dance like a pro. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4455daaf58c62a24a21eb34fcd3bb907","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":" I have a cat named RiceCake. I love tennis, snowboarding, and swimming. I play Just Dance like a pro. ","tags":null,"title":"My Cat \"RiceCake\"","type":"authors"},{"authors":["Zhuangdi Zhu","Kaxiang Lin","Anil K. Jain","Jiayu Zhou"],"categories":null,"content":"","date":1695445700,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695445700,"objectID":"70e61dde6d1e55dceb18c51e7086e0a0","permalink":"https://zhuangdizhu.github.io/publication/rlsurvey/","publishdate":"2023-09-23T13:08:20+08:00","relpermalink":"/publication/rlsurvey/","section":"publication","summary":"Reinforcement learning is a learning paradigm for solving sequential decision-making problems. Recent years have witnessed remarkable progress in reinforcement learning upon the fast development of deep neural networks. Along with the promising prospects of reinforcement learning in numerous domains such as robotics and game-playing, transfer learning has arisen to tackle various challenges faced by reinforcement learning, by transferring knowledge from external expertise to facilitate the efficiency and effectiveness of the learning process. In this survey, we systematically investigate the recent progress of transfer learning approaches in the context of deep reinforcement learning. Specifically, we provide a framework for categorizing the state-of-the-art transfer learning approaches, under which we analyze their goals, methodologies, compatible reinforcement learning backbones, and practical applications. We also draw connections between transfer learning and other relevant topics from the reinforcement learning perspective and explore their potential challenges that await future research progress.","tags":["Reinforcement Learning","Knowledge Transfer","Survey"],"title":"Transfer Learning in Deep Reinforcement Learning: A Survey","type":"publication"},{"authors":["Shuyang Yu","Zhuangdi Zhu","Boyang Liu","Anil K. Jain","Jiayu Zhou"],"categories":null,"content":"","date":1668402500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668402500,"objectID":"4b5711f0fb9d27735fc69ee472f77c3c","permalink":"https://zhuangdizhu.github.io/publication/ruda/","publishdate":"2022-11-14T13:08:20+08:00","relpermalink":"/publication/ruda/","section":"publication","summary":"Unsupervised Domain Adaptation (UDA) provides a promising solution for learning without supervision, which transfers knowledge from relevant source domains with accessible labeled training data. Existing UDA solutions hinge on clean training data with a short-tail distribution from the source domain, which can be fragile when the source domain data is corrupted either inherently or via adversarial attacks. In this work, we propose an effective framework to address the challenges of UDA from corrupted source domains in a principled manner. Specifically, we perform knowledge ensemble from multiple domain-invariant models that are learned on random partitions of training data. To further address the distribution shift from the source to the target domain, we refine each of the learned models via mutual information maximization, which adaptively obtains the predictive information of the target domain with high confidence. Extensive empirical studies demonstrate that the proposed approach is robust against various types of poisoned data attacks while achieving high asymptotic performance on the target domain.","tags":["Unsupervised Domain Adaptation","Robust Learning","Poison Data Attack"],"title":"Robust Unsupervised Domain Adaptation from A Corrupted Source","type":"publication"},{"authors":["Zhuangdi Zhu","Junyuan Hong","steve Drew","Jiayu Zhou"],"categories":null,"content":"","date":1654146500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654146500,"objectID":"cf1c2d6818282152a3069d0398353b0a","permalink":"https://zhuangdizhu.github.io/publication/fedrescue/","publishdate":"2022-06-02T13:08:20+08:00","relpermalink":"/publication/fedrescue/","section":"publication","summary":"The rise of Federated Learning (FL) is bringing machine learning to edge computing by utilizing data scattered across edge devices. However, the heterogeneity of edge network topologies and the uncertainty of wireless transmission are two major obstructions of FL's wide application in edge computing, leading to prohibitive convergence time and high communication cost. In this work, we propose an FL scheme to address both challenges simultaneously. Specifically, we enable edge devices to learn self-distilled neural networks that are readily prunable to arbitrary sizes, which capture the knowledge of the learning domain in a nested and progressive manner. Not only does our approach tackle system heterogeneity by serving edge devices with varying model architectures, but it also alleviates the issue of connection uncertainty by allowing transmitting part of the model parameters under faulty network connections, without wasting the contributing knowledge of the transmitted parameters. Extensive empirical studies show that under system heterogeneity and network instability, our approach demonstrates significant resilience and higher communication efficiency compared to the state-of-the-art.","tags":["Federated Learning","User-Heterogeneity","System Robustness"],"title":"Resilient and Communication Efficient Learning for Heterogeneous Federated Systems","type":"publication"},{"authors":["Zhuangdi Zhu","Kaixiang Lin","Bo Dai","Jiayu Zhou"],"categories":null,"content":"","date":1654146500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654146500,"objectID":"d14ee08fdc9d4b287cdf86b9e749abe1","permalink":"https://zhuangdizhu.github.io/publication/sail/","publishdate":"2022-06-02T13:08:20+08:00","relpermalink":"/publication/sail/","section":"publication","summary":"Reinforcement learning (RL) has demonstrated its superiority in solving sequential decision-making problems. However, heavy dependence on immediate reward feedback impedes the wide application of RL. On the other hand, imitation learning (IL) tackles RL without relying on environmental supervision by leveraging external demonstrations. In practice, however, collecting sufficient expert demonstrations can be prohibitively expensive, yet the quality of demonstrations typically limits the performance of the learning policy. To address a practical scenario, in this work, we propose SelfAdaptive Imitation Learning (SAIL), which, provided with a few demonstrations from a sub-optimal teacher, can perform well in RL tasks with extremely delayed rewards, where the only reward feedback is trajectory-wise ranking. SAIL bridges the advantages of IL and RL by interactively exploiting the demonstrations to catch up with the teacher and exploring the environment to yield demonstrations that surpass the teacher. Extensive empirical results show that not only does SAIL significantly improve the sample efficiency, but it also leads to higher asymptotic performance across different continuous control tasks, compared with the state-of-the-art.","tags":["Imitation Learning","Learning from Suboptimal Knowledge","Exploration in RL","Self-Adaptative Learning"],"title":"Self-Adaptive Imitation Learning: Learning Tasks with Delayed Rewards from Sub-Optimal Demonstrations.","type":"publication"},{"authors":["Junyuan Hong","Zhuangdi Zhu","Shuyang Yu","Zhangyang Wang","Hiroko H Dodge","Jiayu Zhou"],"categories":null,"content":"","date":1628917700,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628917700,"objectID":"31f4c0ae08beb8e14048ca8768152ba1","permalink":"https://zhuangdizhu.github.io/publication/fedebias/","publishdate":"2021-08-14T13:08:20+08:00","relpermalink":"/publication/fedebias/","section":"publication","summary":"Federated learning is a distributed learning framework that is communication efficient and provides protection over participating usersâ€™ raw training data. One outstanding challenge of federate learning comes from the usersâ€™ heterogeneity, and learning from such data may yield biased and unfair models for minority groups. While adversarial learning is commonly used in centralized learning for mitigating bias, there are significant barriers when extending it to the federated framework. In this work, we study these barriers and address them by proposing a novel approach Federated Adversarial DEbiasing (FADE). FADE does not require usersâ€™ sensitive group information for debiasing and offers users the freedom to optout from the adversarial component when privacy or computational costs become a concern. We show that ideally, FADE can attain the same global optimality as the one by the centralized algorithm. We then analyze when its convergence may fail in practice and propose a simple yet effective method to address the problem. Finally, we demonstrate the effectiveness of the proposed framework through extensive empirical studies, including the problem settings of unsupervised domain adaptation and fair learning.","tags":["Federated learning","Data-Heterogeneity","Non-IID"],"title":"Federated adversarial debiasing for fair and transferable representations","type":"publication"},{"authors":["Zhuangdi Zhu","Junyuan Hong","Jiayu Zhou"],"categories":null,"content":"","date":1622610500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622610500,"objectID":"f192962198285231aeb8c533766deb58","permalink":"https://zhuangdizhu.github.io/publication/fedgen/","publishdate":"2021-06-02T13:08:20+08:00","relpermalink":"/publication/fedgen/","section":"publication","summary":"Federated Learning (FL) is a decentralized machine-learning paradigm, in which a global server iteratively averages the model parameters of local users without accessing their data. User heterogeneity has imposed significant challenges to FL, which can incur drifted global models that are slow to converge. Knowledge Distillation has recently emerged to tackle this issue, by refining the server model using aggregated knowledge from heterogeneous users, other than directly averaging their model parameters. This approach, however, depends on a proxy dataset, making it impractical unless such a prerequisite is satisfied. Moreover, the ensemble knowledge is not fully utilized to guide local model learning, which may in turn affect the quality of the aggregated model. Inspired by the prior art, we propose a data-free knowledge distillation approach to address heterogeneous FL, where the server learns a lightweight generator to ensemble user information in a data-free manner, which is then broadcasted to users, regulating local training using the learned knowledge as an inductive bias. Empirical studies powered by theoretical implications show that our approach facilitates FL with better generalization performance using fewer communication rounds, compared with the state-of-the-art.","tags":["Federated learning","Data-Heterogeneity","Non-IID"],"title":"Data-Free Knowledge Distillation for Heterogeneous Federated Learning","type":"publication"},{"authors":["Zhuangdi Zhu","Kaixiang Lin","Bo Dai","Jiayu Zhou"],"categories":null,"content":"","date":1591074500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591074500,"objectID":"f8a6913f2fd18d518550e7d8b1ec9d98","permalink":"https://zhuangdizhu.github.io/publication/opolo/","publishdate":"2020-06-02T13:08:20+08:00","relpermalink":"/publication/opolo/","section":"publication","summary":"Learning from Observations (LfO) is a practical reinforcement learning scenario from which many applications can benefit through the reuse of incomplete resources. Compared to conventional imitation learning (IL), LfO is more challenging because of the lack of expert action guidance. In both conventional IL and LfO, distribution matching is at the heart of their foundation. Traditional distribution matching approaches are sample-costly which depend on on-policy transitions for policy learning. Towards sample-efficiency, some off-policy solutions have been proposed, which, however, either lack comprehensive theoretical justifications or depend on the guidance of expert actions. In this work, we propose a sample-efficient LfO approach which enables off-policy optimization in a principled manner. To further accelerate the learning procedure, we regulate the policy update with an inverse action model, which assists distribution matching from the perspective of mode-covering. Extensive empirical results on challenging locomotion tasks indicate that our approach is comparable with state-of-the-art in terms of both sample-efficiency and asymptotic performance.","tags":["Reinforcement learning","Sample-Efficiency","Partial Observability","Imitation Learning"],"title":"Off-Policy Imitation Learning from Observations","type":"publication"},{"authors":null,"categories":null,"content":"","date":1580083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580083200,"objectID":"97608cdd2a37e1780fe46591f07dbfdf","permalink":"https://zhuangdizhu.github.io/project/federated-learning/","publishdate":"2020-01-27T00:00:00Z","relpermalink":"/project/federated-learning/","section":"project","summary":"On the need of data privacy and more data, we strive to join the knowledge from a fair amount of users to train powerful deep neural networks without sharing data.","tags":["Machine Learning","Federated Learning","Distributed Learning"],"title":"Federated Learning","type":"project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://zhuangdizhu.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538006400,"objectID":"4aef9d19fd9dee16ec71211c4b827fc6","permalink":"https://zhuangdizhu.github.io/project/private-learning/","publishdate":"2018-09-27T00:00:00Z","relpermalink":"/project/private-learning/","section":"project","summary":"On the concern of data privacy, we aim to develop algorithms towards learning accurate models privately from data.","tags":["Machine Learning","Differential Privacy"],"title":"Differentially Private Learning","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"087fe6559a3f9709a3e9dc9f2080d72e","permalink":"https://zhuangdizhu.github.io/project/subspace-learning/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/subspace-learning/","section":"project","summary":"Supervised learning on subspace data which could model real data like skeleton motion.","tags":["Machine Learning"],"title":"Subspace Learning","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://zhuangdizhu.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]